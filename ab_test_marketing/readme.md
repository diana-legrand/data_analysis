# A/B Testing Project

Note: Since GitHub does not render Plotly visualizations properly, it is recommended to view the project via [nbviewer](https://nbviewer.org/github/diana-legrand/data_analysis/blob/main/ab_test_marketing/ab_test_marketing.ipynb).

## Objective

The goal of this project was to evaluate the results of an A/B test using user behavior data, the provided technical brief, and several supporting datasets. In addition to analyzing the test outcomes, it was essential to assess the test’s integrity.
This involved checking for: audience overlap with other concurrent tests, alignment of the test period with marketing campaigns, and potential issues related to the test’s timing boundaries.

## Conclusion

The A/B test revealed statistically significant differences in conversion rates between the control and test groups across all funnel events. However, the expected improvements were not observed—in fact, conversion metrics declined. Moreover, the test was shortened to 23 days instead of the planned 28, and only 5,099 users participated out of the intended 6,000. These deviations suggest that the results may not be fully reliable.

## Tools & Libraries Used
- *pandas*
- *matplotlib*
- *seaborn*
- *plotly*
- *numpy*
- *stats*

## Project Status: Completed.
